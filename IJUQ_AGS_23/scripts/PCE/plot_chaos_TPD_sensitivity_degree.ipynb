{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial chaos sensitivity to the degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we observe the sensitivity of the polynomial chaos expansion to the total degree of the polynomial.\n",
    "More precisely, we observe how this impacts the $Q^2$ predictivity coefficient.\n",
    "\n",
    "We consider the example of the cantilever beam. We create a sparse polynomial chaos with a linear enumeration rule and the family of orthogonal polynomials corresponding to each input variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "import numpy as np\n",
    "import openturns.viewer\n",
    "import pylab as pl\n",
    "pl.rcParams['figure.dpi']= 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameter value leads to fast simulations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDegree = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_alpha = ot.Normal(101.6612, 4.0)\n",
    "distribution_alpha.setDescription([r\"$\\alpha$\"])\n",
    "#\n",
    "distribution_beta = ot.Normal(0.0233, 0.0005)\n",
    "distribution_beta.setDescription([r\"$\\beta$\"])\n",
    "#\n",
    "distribution_epsilon_e = ot.Triangular(0.2, 0.3, 0.5)\n",
    "distribution_epsilon_e.setDescription([r\"$\\epsilon_e$\"])\n",
    "#\n",
    "distribution_epsilon_c = ot.Triangular(0.0, 0.05, 0.3)\n",
    "distribution_epsilon_c.setDescription([r\"$\\epsilon_c$\"])\n",
    "#\n",
    "dp_factor = 1.0e-6\n",
    "distribution_dp = ot.Triangular(0.5 * dp_factor, 5.0 * dp_factor, 10.0 * dp_factor)\n",
    "distribution_dp.setDescription([r\"$d_p$\"])\n",
    "#\n",
    "distribution_gamma_p0 = ot.Triangular(1.0e-09, 4.5e-09, 8.0e-09)\n",
    "distribution_gamma_p0.setDescription([r\"$\\Gamma_p(0)$\"])\n",
    "#\n",
    "distribution_av = ot.Triangular(0.1e-4, 7.8e-4, 12e-4)\n",
    "distribution_av.setDescription([r\"$a_v$\"])\n",
    "#\n",
    "distributionList = [\n",
    "    distribution_alpha,\n",
    "    distribution_beta,\n",
    "    distribution_epsilon_e,\n",
    "    distribution_epsilon_c,\n",
    "    distribution_dp,\n",
    "    distribution_gamma_p0,\n",
    "    distribution_av,\n",
    "]\n",
    "\n",
    "distribution = ot.ComposedDistribution(distributionList)\n",
    "# Workaround for https://github.com/openturns/openturns/issues/2255\n",
    "labels = [marginal.getDescription()[0] for marginal in distributionList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special focus is given to the hot leg\n",
    "dataset_HL = ot.Sample.ImportFromCSVFile('../../data/SG_MC_HL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSample = dataset_HL[:,0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputSample = dataset_HL[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr><th></th><th>data_0</th><th>data_1</th><th>data_2</th><th colspan=\"1\">...</th><th>data_4</th><th>data_5</th><th>data_6</th></tr>\n",
       "  <tr><th>0</th><td>105.5158</td><td>0.02256372</td><td>0.4278621<td colspan=\"1\">...</td><td>6.743093e-06</td><td>4.084868e-09</td><td>0.0006102504</td></tr>\n",
       "  <tr><th>1</th><td>105.4723</td><td>0.02395984</td><td>0.2579091<td colspan=\"1\">...</td><td>4.75128e-06</td><td>4.595586e-09</td><td>0.0008317861</td></tr>\n",
       "  <tr><th>2</th><td>95.00861</td><td>0.02349493</td><td>0.3761768<td colspan=\"1\">...</td><td>3.624861e-06</td><td>3.239612e-09</td><td>0.0005226353</td></tr>\n",
       "<tr><td colspan=\"8\">...</td></tr>\n",
       "  <tr><th>966</th><td>98.22617</td><td>0.02261063</td><td>0.2755298<td colspan=\"1\">...</td><td>1.656015e-06</td><td>4.567305e-09</td><td>0.0005745374</td></tr>\n",
       "  <tr><th>967</th><td>99.8236</td><td>0.02395134</td><td>0.2309162<td colspan=\"1\">...</td><td>3.954574e-06</td><td>1.33652e-09</td><td>0.0005435764</td></tr>\n",
       "  <tr><th>968</th><td>97.46086</td><td>0.02251348</td><td>0.3653241<td colspan=\"1\">...</td><td>8.157586e-06</td><td>1.642326e-09</td><td>0.0004447967</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "class=Sample name=Unnamed implementation=class=SampleImplementation name=Unnamed size=969 dimension=7 description=[data_0,data_1,data_2,...,data_4,data_5,data_6] data=[[105.516,0.0225637,0.427862,...,6.74309e-06,4.08487e-09,0.00061025],[105.472,0.0239598,0.257909,...,4.75128e-06,4.59559e-09,0.000831786],[95.0086,0.0234949,0.376177,...,3.62486e-06,3.23961e-09,0.000522635],...,[98.2262,0.0226106,0.27553,...,1.65602e-06,4.5673e-09,0.000574537],[99.8236,0.0239513,0.230916,...,3.95457e-06,1.33652e-09,0.000543576],[97.4609,0.0225135,0.365324,...,8.15759e-06,1.64233e-09,0.000444797]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputSample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates a sparse polynomial chaos with a given total degree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeSparseLeastSquaresChaos(\n",
    "    inputTrain, outputTrain, multivariateBasis, totalDegree, distribution\n",
    "):\n",
    "    \"\"\"\n",
    "      Create a sparse polynomial chaos based on least squares.\n",
    "\n",
    "      * Uses the enumerate rule in basis.\n",
    "      * Uses the LeastSquaresStrategy to compute the coefficients based on\n",
    "        least squares.\n",
    "      * Uses LeastSquaresMetaModelSelectionFactory to use the LARS selection method.\n",
    "      * Uses FixedStrategy in order to keep all the coefficients that the\n",
    "        LARS method selected.\n",
    "\n",
    "    Source : https://openturns.github.io/openturns/latest/auto_meta_modeling/polynomial_chaos_metamodel/plot_chaos_cv.html\n",
    "    with a bug fix: replace getStrataCumulatedCardinal with getBasisSizeFromTotalDegree\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      inputTrain : Sample\n",
    "          The input design of experiments.\n",
    "      outputTrain : Sample\n",
    "          The output design of experiments.\n",
    "      multivariateBasis : Basis\n",
    "          The multivariate chaos basis.\n",
    "      totalDegree : int\n",
    "          The total degree of the chaos polynomial.\n",
    "      distribution : Distribution.\n",
    "          The distribution of the input variable.\n",
    "\n",
    "      Returns\n",
    "      -------\n",
    "      result : PolynomialChaosResult\n",
    "          The estimated polynomial chaos.\n",
    "    \"\"\"\n",
    "    selectionAlgorithm = ot.LeastSquaresMetaModelSelectionFactory()\n",
    "    projectionStrategy = ot.LeastSquaresStrategy(\n",
    "        inputTrain, outputTrain, selectionAlgorithm\n",
    "    )\n",
    "    enumerateFunction = multivariateBasis.getEnumerateFunction()\n",
    "    basisSize = enumerateFunction.getBasisSizeFromTotalDegree(totalDegree)  # OK\n",
    "    adaptiveStrategy = ot.FixedStrategy(multivariateBasis, basisSize)\n",
    "    chaosalgo = ot.FunctionalChaosAlgorithm(\n",
    "        inputTrain, outputTrain, distribution, adaptiveStrategy, projectionStrategy\n",
    "    )\n",
    "    chaosalgo.run()\n",
    "    result = chaosalgo.getResult()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the sparsity rate of the polynomial chaos.\n",
    "To do this, we compute the number of coefficients in the decomposition assuming a linear enumeration rule and a fixed truncation.\n",
    "The sparsity rate is the complement of the ratio between the number of coefficients\n",
    "selected from LARS and the total number of coefficients in the full polynomial basis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSparsityRate(multivariateBasis, totalDegree, chaosResult):\n",
    "    \"\"\"Compute the sparsity rate, assuming a FixedStrategy.\"\"\"\n",
    "    # Get P, the maximum possible number of coefficients\n",
    "    enumfunc = multivariateBasis.getEnumerateFunction()\n",
    "    P = enumfunc.getStrataCumulatedCardinal(totalDegree)\n",
    "    # Get number of coefficients in the selection\n",
    "    indices = chaosResult.getIndices()\n",
    "    nbcoeffs = indices.getSize()\n",
    "    # Compute rate\n",
    "    sparsityRate = 1.0 - nbcoeffs / P\n",
    "    return sparsityRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions compute and plot the Q2 predictivity coefficients within the validation plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeQ2Chaos(chaosResult, inputTest, outputTest, outputMarginalIndex = 0):\n",
    "    \"\"\"Compute the Q2 of a chaos.\"\"\"\n",
    "    outputDimension = outputTest.getDimension()\n",
    "    if outputMarginalIndex > outputDimension:\n",
    "        raise ValueError(\"Output marginal index \", outputMarginalIndex, \" is greater than the output dimension \", \n",
    "                         outputDimension)\n",
    "    metamodel = chaosResult.getMetaModel()\n",
    "    val = ot.MetaModelValidation(inputTest, outputTest, metamodel)\n",
    "    Q2 = val.computePredictivityFactor()[outputMarginalIndex]\n",
    "    Q2 = max(Q2, 0.0)  # We are not lucky every day.\n",
    "    return Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printChaosStats(multivariateBasis, chaosResult, inputTest, outputTest, totalDegree, outputMarginalIndex = 0):\n",
    "    \"\"\"Print statistics of a chaos.\"\"\"\n",
    "    outputDimension = outputTest.getDimension()\n",
    "    if outputMarginalIndex > outputDimension:\n",
    "        raise ValueError(\"Output marginal index \", outputMarginalIndex, \" is greater than the output dimension \", \n",
    "                         outputDimension)\n",
    "    sparsityRate = computeSparsityRate(multivariateBasis, totalDegree, chaosResult)\n",
    "    Q2 = computeQ2Chaos(chaosResult, inputTest, outputTest, outputMarginalIndex)\n",
    "    metamodel = chaosResult.getMetaModel()\n",
    "    val = ot.MetaModelValidation(inputTest, outputTest, metamodel)\n",
    "    graph = val.drawValidation().getGraph(0, outputMarginalIndex)\n",
    "    legend1 = \"O=%d, D=%d, Q2=%.2f%%\" % (outputMarginalIndex, totalDegree, 100 * Q2)\n",
    "    graph.setLegends([\"\", legend1])\n",
    "    graph.setLegendPosition(\"topleft\")\n",
    "    print(\n",
    "        \"Degree=%d, Q2=%.2f%%, Sparsity=%.2f%%\"\n",
    "        % (totalDegree, 100 * Q2, 100 * sparsityRate)\n",
    "    )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariateBasis = ot.OrthogonalProductPolynomialFactory(\n",
    "    distributionList\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q2_score_by_splitting(\n",
    "    X, Y, basis, totalDegree, distribution, split_fraction=0.75\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute Q2 score by splitting into train/test sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Sample(size, input_dimension)\n",
    "        The X dataset.\n",
    "    Y : Sample(size, output_dimension)\n",
    "        The Y dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q2_score : float\n",
    "        The Q2 score.\n",
    "    \"\"\"\n",
    "\n",
    "    training_sample_size = X.getSize()\n",
    "    X_train = ot.Sample(X)\n",
    "    Y_train = ot.Sample(Y)\n",
    "    split_index = int(split_fraction * training_sample_size)\n",
    "    X_test = X_train.split(split_index)\n",
    "    Y_test = Y_train.split(split_index)\n",
    "    chaosResult = ComputeSparseLeastSquaresChaos(\n",
    "        X_train, Y_train, basis, totalDegree, distribution\n",
    "    )\n",
    "    metamodel = chaosResult.getMetaModel()\n",
    "    val = ot.MetaModelValidation(X_test, Y_test, metamodel)\n",
    "    Q2_score = val.computePredictivityFactor()\n",
    "    print('Here')\n",
    "    Q2_local_mean = Q2_score.norm1() / Q2_score.getDimension()\n",
    "    return Q2_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalDegree =  1\n",
      "  Train\n",
      "  Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mWRN - set the component 26 of contributor 1=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 53 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 54 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 55 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 56 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 57 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 58 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 59 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 60 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 61 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 62 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 63 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 64 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 65 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 66 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 67 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 68 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 69 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 70 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 71 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 72 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 73 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 74 of contributor 2=0 to zero as it is too small\u001b[0m\n",
      "\u001b[34m\u001b[1mWRN - set the component 26 of contributor 1=0 to zero as it is too small"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree=1, Q2=52.10%, Sparsity=12.50%\n",
      "totalDegree =  2\n",
      "  Train\n"
     ]
    }
   ],
   "source": [
    "split_fraction = 0.75\n",
    "training_sample_size = inputSample.getSize()\n",
    "outputMarginalIndex = 0\n",
    "fig = pl.figure(figsize=(25, 4))\n",
    "for totalDegree in range(1, maxDegree + 1):\n",
    "    print(\"totalDegree = \", totalDegree)\n",
    "    print(\"  Train\")\n",
    "    X_train = ot.Sample(inputSample)\n",
    "    Y_train = ot.Sample(outputSample)\n",
    "    split_index = int(split_fraction * training_sample_size)\n",
    "    X_test = X_train.split(split_index)\n",
    "    Y_test = Y_train.split(split_index)\n",
    "    chaosResult = ComputeSparseLeastSquaresChaos(\n",
    "        X_train, Y_train, multivariateBasis, totalDegree, distribution\n",
    "    )\n",
    "    print(\"  Test\")\n",
    "    graph = printChaosStats(\n",
    "        multivariateBasis, chaosResult, X_test, Y_test, totalDegree, outputMarginalIndex\n",
    "    )\n",
    "    ax = fig.add_subplot(1, maxDegree, totalDegree)\n",
    "    _ = ot.viewer.View(graph, figure=fig, axes=[ax])\n",
    "    pl.suptitle(\"Metamodel validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : loop over the output marginal indices ?\n",
    "# TODO : grid of graphs with outputDimension rows ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2_score = compute_Q2_score_by_splitting(inputSample, outputSample_BC, multivariateBasis, totalDegree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when the degree of the polynomial increases, the Q2 coefficient decreases.\n",
    "We also see that the sparsity rate increases: while the basis size grows rapidly with the degree, the algorithm selects a smaller fraction of this basis.\n",
    "This shows that the algorithm performs its task of selecting relevant coefficients.\n",
    "However, this selection does not seem to be sufficient to mitigate the large number of coefficients.\n",
    "\n",
    "Of course, this example is designed to make a predictivity decrease gradually.\n",
    "We are going to see that this situation is actually easy to reproduce.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the predictivity coefficient\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us repeat the following experiment to see the variability of the Q2 coefficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSampleQ2(inputSample, outputSample, numberAttempts, maxDegree, split_fraction = 0.75):\n",
    "    \"\"\"\n",
    "    For a given sample size N, for degree from 1 to maxDegree,\n",
    "    repeat the following experiment numberAttempts times:\n",
    "    create a sparse least squares chaos and compute the Q2\n",
    "    using n_valid points.\n",
    "    \"\"\"\n",
    "    sampleSize = inputSample.getSize()\n",
    "    mixingDistribution = ot.KPermutationsDistribution(sampleSize, sampleSize)\n",
    "    Q2sample = ot.Sample(numberAttempts, maxDegree)\n",
    "    for totalDegree in range(maxDegree, maxDegree + 1):\n",
    "        print(\"Degree = %d\" % (totalDegree))\n",
    "        for i in range(numberAttempts):\n",
    "            # Randomize the sample\n",
    "            X_train = ot.Sample(inputSample)\n",
    "            Y_train = ot.Sample(outputSample)\n",
    "            newIndices = mixingDistribution.getRealization()\n",
    "            X_train = X_train[newIndices]\n",
    "            Y_train = Y_train[newIndices]\n",
    "            # Split\n",
    "            split_index = int(split_fraction * sampleSize)\n",
    "            X_test = X_train.split(split_index)\n",
    "            Y_test = Y_train.split(split_index)\n",
    "            # Train\n",
    "            chaosResult = ComputeSparseLeastSquaresChaos(\n",
    "                X_train, Y_train, multivariateBasis, totalDegree, distribution\n",
    "            )\n",
    "            # Test\n",
    "            Q2sample[i, totalDegree - 1] = compute_Q2_score_by_splitting(\n",
    "                X_test, Y_test, multivariateBasis, totalDegree, distribution, split_fraction=0.75\n",
    "            )\n",
    "    return Q2sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.75\n",
    "training_sample_size = inputSample.getSize()\n",
    "outputMarginalIndex = 0\n",
    "fig = pl.figure(figsize=(25, 4))\n",
    "for totalDegree in range(4, 5):\n",
    "    print(\"totalDegree = \", totalDegree)\n",
    "    print(\"  Train\")\n",
    "    X_train = ot.Sample(inputSample)\n",
    "    Y_train = ot.Sample(outputSample)\n",
    "    split_index = int(split_fraction * training_sample_size)\n",
    "    X_test = X_train.split(split_index)\n",
    "    Y_test = Y_train.split(split_index)\n",
    "    chaosResult = ComputeSparseLeastSquaresChaos(\n",
    "        X_train, Y_train, multivariateBasis, totalDegree, distribution\n",
    "    )\n",
    "    print(\"  Test\")\n",
    "    graph = printChaosStats(\n",
    "        multivariateBasis, chaosResult, X_test, Y_test, totalDegree, outputMarginalIndex\n",
    "    )\n",
    "    ax = fig.add_subplot(1, maxDegree, totalDegree)\n",
    "    _ = ot.viewer.View(graph, figure=fig, axes=[ax])\n",
    "    pl.suptitle(\"Metamodel validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function uses a boxplot to see the distribution of the Q2 coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberAttempts = 15  # Number of repetitions\n",
    "\n",
    "Q2sample = computeSampleQ2(inputSample, outputSample, numberAttempts, maxDegree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberAttempts = 15  # Number of repetitions\n",
    "\n",
    "Q2sample_1 = computeSampleQ2(inputSample, outputSample, numberAttempts, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotQ2Boxplots(Q2sample, N):\n",
    "    data = np.array(Q2sample)\n",
    "    pl.figure()\n",
    "    pl.boxplot(data)\n",
    "    pl.title(r\"Hot branch at $z_{max}$, time-average of $Q^2$, PCE training sample size = %d\" % N,fontsize=7)\n",
    "    pl.xlabel(r\"$p$\")\n",
    "    pl.ylabel(r\"$m(Q^2)\\;(\\%)$\")\n",
    "    pl.ylim(0.0,1.0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment is repeated several times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2sample_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when the size of the design of experiments is as small as 20, it is more appropriate to use a very low degree polynomial. Here 1 performs best and 4 is risky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(0.75*969)  # size of the train design\n",
    "data_BF, data_BC = np.array(Q2sample), np.array(Q2sample_1)\n",
    "\n",
    "fig, ax = pl.subplots(1,2,figsize=(10,5), layout='tight')\n",
    "ax[0].boxplot(data_BC)\n",
    "ax[0].set_title(r\"Hot branch at $z_{max}$\")\n",
    "ax[0].set_ylim(0.0,1.0)\n",
    "ax[0].set_xlabel(r\"$p$\")\n",
    "ax[0].set_ylabel(r\"$m(Q^2)\\;(\\%)$\")\n",
    "\n",
    "ax[1].boxplot(data_BF)\n",
    "ax[1].set_title(r\"Cold branch at $z_{max}$\")\n",
    "ax[1].set_ylim(0.0,1.0)\n",
    "ax[1].set_xlabel(r\"$p$\")\n",
    "ax[1].set_ylabel(r\"$m(Q^2)\\;(\\%)$\")\n",
    "\n",
    "fig.suptitle(r\"TPD-PCE time-average of $Q^2$ as a function of degree $p$\")\n",
    "\n",
    "fig.savefig('TPD_pce_degree_sensitivit.png',format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a 30-point design set, a polynomial degree of 2 is usually advisable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50  # size of the train design\n",
    "Q2sample = computeSampleQ2(N, n_valid, numberAttempts, maxDegree)\n",
    "plotQ2Boxplots(Q2sample, N)\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the sample size increases, the Q2 computation becomes less sensitive to the polynomial degree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We observe that on the cantilever beam example, to use a polynomial total\n",
    "degree equal to 4, we need a sample size at least equal to 50 to get a\n",
    "satisfactory and reproducible Q2.\n",
    "When the degree is equal to 4, if the sample is small, then depending on the\n",
    "particular sample, the predictivity coefficient can be very low (i.e. less than 0.5).\n",
    "With a sample size as small as 20, a polynomial degree of 1 is safer.\n",
    "However the limited sample size may have an impact on other statistics that\n",
    "could be derived from a metamodel calculated on such a small training sample.\n",
    "\n",
    "## References\n",
    "\n",
    "* \"Metamodel-Based Sensitivity Analysis: Polynomial Chaos Expansions and Gaussian Processes\", Lo√Øc Le Gratiet, Stefano Marelli, Bruno Sudret,\n",
    "  Handbook of Uncertainty Quantification, 2017, Springer International Publishing.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
